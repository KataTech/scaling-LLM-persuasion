TRUE ~ issue
))
# Plot
out_plot_pi <-
map(x_scale,
function(.x) {
last_points <-
df_res_issues %>%
unnest(cols = pred_values) %>%
group_by(issue) %>%
summarize(max_param = max(param_count_in_b, na.rm = TRUE),
last_pred = last(pred[param_count_in_b == max_param])) %>%
ungroup()
g <-
df_res_issues %>%
unnest(cols = pred_values) %>%
# mutate(issue = str_replace_all(issue, "_", " ")) %>%
ggplot(aes(x = param_count_in_b, y = pred, color = issue)) +
scale_color_manual(values = issue_colors) +
theme_bw() +
theme_bw(base_family = "Times New Roman") +
geom_line(linewidth = .5) +
# Add average line
geom_line(data = df_pi_out_summary,
aes(x = param_count_in_b, y = pred),
inherit.aes = F, linewidth = 2, linetype = "twodash", alpha = 1, color = "#cc3224") +
# Add prediction interval
geom_ribbon(data = df_pi_out_summary,
aes(x = param_count_in_b, ymin = .lower, ymax = .upper),
inherit.aes = F, fill = "#232323", alpha = 0.06) +
theme(panel.grid.minor = element_blank(),
panel.grid.major = element_blank(),
element_text(
family = "Times New Roman",
size = 22),
axis.title = element_text(
family = "Times New Roman",
size = 22),
axis.line = element_line(color = "black", size = 0.25),
panel.border = element_blank(),
plot.title = element_text(hjust = 0.5, face = "bold", size = 24),
legend.position = "none",
plot.margin = unit(c(1, 6, 1, 1), "lines"),
axis.text = element_text(size = 22)) +
geom_hline(yintercept = 0, linetype = "dashed") +
labs(x = "\nModel Parameters (Billions)",
y = "Estimated Persuasive Impact in Percentage Points (95% CI)\n",
title = paste0(str_to_sentence(.x), " scale"),
color = "Issue")
if (.x != "log") { # Only add labels when .x is not "log"
g <- g + geom_text(data = last_points, aes(x = max_param, y = last_pred, label = issue),
family = "Times New Roman",
fontface = "bold", color = issue_colors[last_points$issue], hjust = -0.1, size = 5) +
coord_cartesian(clip = "off") +
theme(plot.margin = unit(c(1, 8.5, 1, 1), "lines"))
}
if(.x == "log") {
g <-
g +
scale_x_continuous(trans = "log10", breaks = c(0.1, 1, 10, 100, max(df_pi_out_summary$param_count_in_b, na.rm = T)))
}
g
})
# Join plots and save
g <-
plot_grid(out_plot_pi[[1]] +
annotate(geom = "text",
label = "",
x = 1, y = -3, fontface = "bold", hjust = 0),
out_plot_pi[[2]] +
labs(y = "\n") +
theme(axis.text.y = element_blank(),
axis.ticks.y = element_blank(),
legend.position = "none"),
labels = c("A","B"), label_size = 18, label_fontfamily = "Times New Roman")
ggsave(plot = g, filename = "output/plots/issue_plot.pdf", height = 8, width = 18)
# Get tables ----
# > Primary model results ----
# Tidy fixed effects for all models
df_combos <-
df_combos %>%
mutate(fixef_tidied = map(df_combos$model_fit, ~.x %>% tidy))
# Get random effects for primary model
# Note we currently only get these for the linear 300B-frontier model
model_x <-
df_combos %>%
filter(specification == "linear", frontier_params_in_b == 300) %>%
pull(model_fit) %>% .[[1]]
# Get confidence intervals
# Note: this took ~2 hours on a 2022 M1 Macbook Pro
# So I've written it out for now
if(run_get_cis) {
model_x_cis <- confint(model_x)
df_model_x_cis <-
model_x_cis %>%
as.data.frame %>%
data.frame %>%
rownames_to_column %>%
filter(str_detect(rowname, "2.", negate = T))
df_rfx <-
bind_rows(
data.frame(
coef = "intrcpt",
param = "tau",
group = c(model_x$s.names %>% unname %>% .[1],
model_x$s.names %>% unname %>% .[2]),
estimate = c(model_x$sigma2 %>% sqrt %>% .[1],
model_x$sigma2 %>% sqrt %>% .[2])
),
data.frame(
coef = model_x$g.names %>% unname %>% .[1:2],
param = "tau",
group = model_x$g.names %>% unname %>% .[3],
estimate = c(model_x$tau2 %>% sqrt %>% .[1],
model_x$tau2 %>% sqrt %>% .[2])
),
data.frame(
coef = "[intrcpt, log(parameter count)]",
param = "rho",
group = "issue",
estimate = model_x$rho
)
) %>%
mutate(coef = case_when(str_detect(coef, "poly") ~ "log(parameter count)", T ~ coef)) %>%
select(group, coef, param, estimate) %>%
add_column(.before = "group", effect = "random")
# Add CIs
df_rfx <- df_rfx %>% bind_cols(df_model_x_cis %>% select(contains("ci")))
tidied_model_x <- tidy(model_x)
# Combine random and fixed effects into table
out_table <-
bind_rows(
data.frame(
effect = "fixed",
group = NA,
coef = c("intrcpt", "log(parameter count)"),
param = c("mu", "mu"),
estimate = c(tidied_model_x[[1,"estimate"]],
tidied_model_x[[2,"estimate"]]),
se = c(tidied_model_x[[1,"std.error"]],
tidied_model_x[[2,"std.error"]]),
p = c(tidied_model_x[[1,"p.value"]],
tidied_model_x[[2,"p.value"]])
) %>%
mutate(ci.lb = estimate - 1.96*se,
ci.ub = estimate + 1.96*se),
df_rfx
) %>%
select(-se)
# Tidy numbers and write to file
out_table <-
out_table %>%
mutate(p = case_when(p < .001 ~ "<.001", T ~ as.character(round(p, 3)))) %>%
mutate(across(where(is.numeric), ~ round(.x, 2))) %>%
mutate(`95% CI` = paste0("[", ci.lb, ", ", ci.ub, "]")) %>%
select(-ci.lb, -ci.ub)
write.csv(out_table, "output/tables/table_primary_model.csv", row.names = F)
} else { print("Note: re-running the primary model table is set to <<FALSE>>") }
# > Sensitivity analysis for # frontier model parameters ----
# Make table
robust_frontier_table <-
pmap(df_combos %>% filter(specification == "linear") %>% select(frontier_params_in_b, model_fit),
~tidy(..2) %>% mutate("Frontier parameters (in B)" = ..1)) %>%
bind_rows() %>%
filter(term != "intercept") %>%
mutate(term = "log(parameter count)") %>%
select(`Frontier parameters (in B)`, term, estimate, std.error, p.value) %>%
mutate(p.value = case_when(p.value < .001 ~ "<.001", T ~ as.character(round(p.value, 3)))) %>%
mutate(across(where(is.numeric), ~ round(.x, 2)))
write.csv(robust_frontier_table, "output/tables/table_robust_frontier.csv", row.names = F)
# > Other models ----
df_combos$specification %>% unique
list_models <- c("cubic", "quadratic", "family_fixed_fx", "drop_pythia70m",
"mediators_joint", "primary_adjust2", "task_comp2_alone", "primary_adjust3")
map(list_models,
function(.x) {
out_table <-
df_combos %>%
filter(specification == .x) %>%
pull(fixef_tidied) %>%
.[[1]]
if(.x == "mediators_joint") {
out_table <-
out_table %>%
mutate(`95% CI adjusted` = paste0("[",
format(round(estimate - critval*std.error, 2), nsmall = 2), ", ",
format(round(estimate + critval*std.error, 2), nsmall = 2),
"]"))
}
out_table <-
out_table %>%
#add_column(specification = .x, .before = "term") %>%
mutate(p.value = case_when(p.value < .001 ~ "<.001", T ~ format(round(p.value, 3), nsmall = 2))) %>%
mutate(across(where(is.numeric), ~ format(round(.x, 2), nsmall = 2))) %>%
select(-type)
write.csv(out_table,
paste0("output/tables/table_", .x, ".csv"),
row.names = F)
})
library(tidyverse)
library(metafor)
library(broom)
library(estimatr)
library(ggrepel)
library(cowplot)
library(patchwork)
library(nlme)
set.seed(42)
# Data ----
df_for_model <- readRDS("output/processed_data/prepared_data.rds")
# Wrangle
df_for_model2 <-
df_for_model %>%
filter(condition == "AI") %>%
mutate(parameters = ifelse(is.na(parameters), 300, parameters))
# Specifications ----
specifications <-
tribble(
~specification,      ~model_function,                               ~start_values,
"log-linear",        "a + b * log(parameters)",                     c(a_start = 1, b_start = 1),
"power law",         "a * parameters^b",                            c(a_start = 50, b_start = 0.5),
"saturating growth", "a * (1 - exp(-b * parameters))",              c(a_start = 50, b_start = 1),
"logistic",          "a / (1 + exp(-b * (parameters - c)))",        c(a_start = 50, b_start = 1, c_start = 1),
"log-logistic",      "a / (1 + exp(-b * (log(parameters) - c)))",   c(a_start = 50, b_start = 1, c_start = 1)
)
# Iterate and fit models ----
newdata <-
data.frame(parameters = seq(from = min(df_for_model2$parameters),
to = max(df_for_model2$parameters),
length.out = 5000))
list_models <- df_for_model2 %>% pull(model) %>% unique # For CV
list_out <- list()
for (i in 1:nrow(specifications)) {
id_spec     <- specifications[[i,"specification"]]
id_function <- specifications[[i,"model_function"]]
id_start    <- specifications[[i,"start_values"]][[1]]
model_formula <- as.formula(paste0("dv_response_mean ~ ", id_function))
if(id_spec == "log-log") {
model_formula <- as.formula(paste0("log(dv_response_mean + 1) ~ ", id_function))
}
# Fit model!
if(str_detect(id_spec, "logistic")) {
out_fit <-
nls(
model_formula,
data = df_for_model2,
start = c(a = id_start[["a_start"]],
b = id_start[["b_start"]],
c = id_start[["c_start"]]),
)
}
if(str_detect(id_spec, "logistic", negate = T)) {
out_fit <-
nls(
model_formula,
data = df_for_model2,
start = c(a = id_start[["a_start"]], b = id_start[["b_start"]])
)
}
# > Predicted values ----
df_pred <-
predict(out_fit, level = 0, newdata = newdata) %>%
as.data.frame() %>%
bind_cols(newdata) %>%
mutate(model = id_spec)
names(df_pred)[1] <- "pred_value"
# > Cross-validation (leave-one-model-out) ----
cv_error <-
map_dbl(list_models,
function(holdout_model) {
#holdout_model <- list_models[24] # COMMENT THIS OUT!
df_train <- df_for_model2 %>% filter(!(model %in% holdout_model))
df_test  <- df_for_model2 %>% filter(model %in% holdout_model)
if(str_detect(id_spec, "logistic")) {
out_train <-
nls(
model_formula,
data = df_train,
start = c(a = id_start[["a_start"]],
b = id_start[["b_start"]],
c = id_start[["c_start"]]),
)
}
if(str_detect(id_spec, "logistic", negate = T)) {
out_train <-
nls(
model_formula,
data = df_train,
start = c(a = id_start[["a_start"]], b = id_start[["b_start"]])
)
}
# Predict on heldout data
out_train_pred <- predict(out_train, level = 0, newdata = df_test)
# Compute prediction error for model
pred_error <- abs(mean(df_test$dv_response_mean) - mean(out_train_pred))
pred_error # Return
}) %>% mean() # Compute mean prediction error across model folds
# Return
list_out[[i]] <-
list("model_fit" = out_fit,
"pred_values" = df_pred,
"cv_error" = cv_error)
}
specifications$model_fit   <- map(list_out, ~.x$model_fit)
specifications$pred_values <- map(list_out, ~.x$pred_values)
specifications$cv_error    <- map_dbl(list_out, ~.x$cv_error)
# Write AIC/BIC/CV-error ----
out_aic_bic <-
map(1:nrow(specifications),
function(.x) {
list("AIC" = AIC(specifications$model_fit[[.x]]),
"BIC" = BIC(specifications$model_fit[[.x]]))
})
# Write table to file
data.frame("Model" = specifications$specification,
"AIC" = map_dbl(out_aic_bic, ~.x$AIC),
"BIC" = map_dbl(out_aic_bic, ~.x$BIC),
"CV_error" = specifications$cv_error) %>%
arrange(AIC) %>%
mutate_if(is.numeric, ~format(round(., 2), nsmall = 2)) %>%
write_csv("output/tables/nonlinear_comparisons.csv")
# Write coefficient estimates ----
map(1:nrow(specifications),
function(.x) {
out <- specifications$model_fit[[.x]] %>% tidy
out %>%
mutate(Model = specifications$specification[[.x]]) %>%
select(Model, everything()) %>%
mutate(`p.value` = case_when(
`p.value` <.001 ~ "<.001",
T ~ format(round(`p.value`, 3), nsmall = 3)
)) %>%
mutate_if(is.numeric, ~format(round(., 2), nsmall = 2))
}) %>%
bind_rows() %>%
write_csv("output/tables/nonlinear_results.csv")
# Plot ----
# Get raw mean outcome for each model
model_mean_y <-
df_for_model2 %>%
reframe(pred_value = mean(dv_response_mean),
param_in_b = first(parameters),
.by = "model")
# Mean attitude in control group
control_mean <-
df_for_model %>%
filter(condition == "control") %>%
pull(dv_response_mean) %>%
mean()
# Plot predicted values and overlay raw means
out_plots <-
map(c("Linear scale", "Log scale"),
function(.x) {
g <-
specifications %>%
unnest(cols = pred_values) %>%
rename(param_in_b = parameters) %>%
ggplot(aes(x = param_in_b, y = pred_value, color = model)) +
geom_line(size = 1.5, alpha = 0.6) +
labs(x = "Model parameters (billions)",
y = "Policy attitude (0-100 scale)",
color = "Model",
title = .x) +
theme_bw() +
coord_cartesian(ylim = c(45, 60)) +
geom_hline(yintercept = control_mean, linewidth = 1, alpha = 0.5) +
geom_point(data = model_mean_y,
aes(x = param_in_b, y = pred_value),
inherit.aes = F,
alpha = 0.5,
size = 3) +
geom_text_repel(data = model_mean_y,
aes(x = param_in_b, y = pred_value, label = model),
inherit.aes = F) +
theme(legend.position = c(0.85, 0.5),
legend.box.background = element_rect(),
plot.title = element_text(hjust = 0.5),
panel.grid.minor = element_blank())
if(.x == "Log scale") {
g <-
g +
scale_x_log10() +
annotate("text", label = "Mean attitude in control group",
x = 100,
y = control_mean - 0.25,
hjust = 1, fontface = "bold") +
annotate("text", label = "Points show mean attitude in LM groups",
x = log(50, 10),
y = 60,
fontface = "bold")
} else {
g <-
g +
theme(legend.position = "none",
axis.ticks.y = element_blank(),
axis.text.y = element_blank()) +
labs(y = "")
}
g
})
g <- plot_grid(out_plots[[2]], out_plots[[1]], labels = "AUTO")
ggsave(plot = g, filename = "output/plots/nonlinear_comparisons.pdf",
height = 7, width = 14)
# Extrapolation exercise ----
extrapolate_specs <- c("log-logistic", "power law", "log-linear", "logistic", "saturating growth")
extrapolate_to_values <- c(3000, 30000) # In billions
df_combos <- expand_grid(extrapolate_specs, extrapolate_to_values)
plot_extrapolation <-
map(1:nrow(df_combos),
function(i) {
extrap_spec  <- df_combos[[i,"extrapolate_specs"]]
extrap_value <- df_combos[[i,"extrapolate_to_values"]]
x <- specifications %>% filter(specification == extrap_spec) %>% pull(model_fit) %>% .[[1]]
newdata2 <-
data.frame(parameters = c(
seq(from = min(df_for_model2$parameters),
to = max(df_for_model2$parameters),
length.out = 100),
seq(from = max(df_for_model2$parameters) + 1,
to = extrap_value,
length.out = 500)))
df_pred2 <-
predict(x, level = 0, newdata = newdata2) %>%
as.data.frame() %>%
bind_cols(newdata2) %>%
set_names("pred_value", "param_in_b")
df_pred2 <-
df_pred2 %>%
mutate(control_mean = control_mean) %>%
mutate(implied_tx = pred_value - control_mean)
max_tx <- df_pred2 %>% slice_max(param_in_b)
obs_tx <- df_pred2 %>% filter(param_in_b == 300)
obs_color <- "blue"
max_color <- "red"
hum_color <- "green4"
human_mean <-
df_for_model %>%
filter(condition == "human") %>%
pull(dv_response_mean) %>%
mean()
g2 <-
df_pred2 %>%
ggplot(aes(x = param_in_b/1000, y = pred_value)) +
theme_bw() +
geom_line() +
geom_point(data = model_mean_y,
aes(x = param_in_b/1000, y = pred_value),
inherit.aes = F,
alpha = 0.3,
size = 3) +
labs(x = "Parameters (in Trillions)",
y = "Policy attitude (0-100 scale)",
title = paste0("Extrapolation of ", extrap_spec, " function")) +
geom_text_repel(data = model_mean_y %>% mutate(model  = ifelse(param_in_b < 300, NA, model)),
aes(x = param_in_b/1000, y = pred_value, label = model),
inherit.aes = F) +
scale_y_continuous(breaks = 46:64) +
theme(panel.grid.minor.y = element_blank(),
plot.title = element_text(hjust = 0.5)) +
# Annotate implied treatment effects
# Full extrapolation:
annotate("segment",
x    = max_tx$param_in_b/1000,
xend = max_tx$param_in_b/1000,
y    = max_tx$control_mean + 0.1,
yend = max_tx$pred_value - 0.1,
arrow = arrow(ends = "both", type = "closed", length = unit(0.02, "npc")),
color = max_color) +
annotate("text",
x = max_tx$param_in_b/1000*0.99,
y = 55,
hjust = 1,
label = paste0("Parameters: ", max_tx$param_in_b/1000, "T (", max_tx$param_in_b, "B)\n",
"Implied treatment effect: ", max_tx$implied_tx %>% round(2), "pp"),
color = max_color) +
# Empirically observed max
annotate("segment",
x    = 300/1000,
xend = 300/1000,
y    = obs_tx$control_mean + 0.1,
yend = obs_tx$pred_value - 0.1,
arrow = arrow(ends = "both", type = "closed", length = unit(0.02, "npc")),
color = obs_color) +
annotate("text",
x = obs_tx$param_in_b/1000*1.05,
y = 52,
hjust = 0,
label = paste0("Parameters: 0.3T (300B)\nImplied treatment effect: ",
obs_tx$implied_tx %>% round(2), "pp"),
color = obs_color) +
# Add human mean
geom_hline(yintercept = human_mean, linewidth = 1, alpha = 0.5,
color = hum_color) +
annotate("text",
x = (extrap_value/1000)/2,
y = human_mean + 0.25,
hjust = 0.5,
label = "Mean attitude in human-message group",
color = hum_color) +
# Control group mean
geom_hline(yintercept = control_mean, linewidth = 1, alpha = 0.5) +
annotate("text",
label = "Mean attitude in control group",
x = (extrap_value/1000)/2,
y = control_mean - 0.25,
hjust = 0.5)
ggsave(plot = g2,
filename = paste0("output/plots/extrapolation_",
str_replace_all(extrap_spec, c("-" = "_", " " = "_")), "_",
extrap_value/1000, "T.pdf"),
height = 7, width = 9)
})

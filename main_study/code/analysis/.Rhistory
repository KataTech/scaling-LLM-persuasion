#
#   out_fit <-
#     nls(
#       model_formula,
#       data = df_for_model2,
#       start = c(L = id_start[["L_start"]],
#                 k = id_start[["k_start"]],
#                 X0 = id_start[["X0_start"]]),
#     )
#
# }
}
specifications$model_fit   <- map(list_out, ~.x$model_fit)
specifications$pred_values <- map(list_out, ~.x$pred_values)
specifications$cv_error    <- map_dbl(list_out, ~.x$cv_error)
# Write AIC/BIC/CV-error ----
out_aic_bic <-
map(1:nrow(specifications),
function(.x) {
list("AIC" = AIC(specifications$model_fit[[.x]]),
"BIC" = BIC(specifications$model_fit[[.x]]))
})
# Write table to file
data.frame("Model" = specifications$specification,
"AIC" = map_dbl(out_aic_bic, ~.x$AIC),
"BIC" = map_dbl(out_aic_bic, ~.x$BIC),
"CV_error" = specifications$cv_error) %>%
arrange(AIC) %>%
mutate_if(is.numeric, ~format(round(., 2), nsmall = 2)) %>%
write_csv("output/tables/nonlinear_comparisons.csv")
# Write coefficient estimates ----
map(1:nrow(specifications),
function(.x) {
out <- specifications$model_fit[[.x]] %>% tidy
out %>%
mutate(Model = specifications$specification[[.x]]) %>%
select(Model, everything()) %>%
mutate(`p.value` = case_when(
`p.value` <.001 ~ "<.001",
T ~ format(round(`p.value`, 3), nsmall = 3)
)) %>%
mutate_if(is.numeric, ~format(round(., 2), nsmall = 2))
}) %>%
bind_rows() %>%
write_csv("output/tables/nonlinear_results.csv")
# Plot ----
# Get raw mean outcome for each model
model_mean_y <-
df_for_model2 %>%
reframe(pred_value = mean(dv_response_mean),
param_in_b = first(parameters),
.by = "model")
# Mean attitude in control group
control_mean <-
df_for_model %>%
filter(condition == "control") %>%
pull(dv_response_mean) %>%
mean()
# Plot predicted values and overlay raw means
out_plots <-
map(c("Linear scale", "Log scale"),
function(.x) {
g <-
specifications %>%
unnest(cols = pred_values) %>%
rename(param_in_b = parameters) %>%
ggplot(aes(x = param_in_b, y = pred_value, color = model)) +
geom_line(size = 1.5, alpha = 0.6) +
labs(x = "Model parameters (billions)",
y = "Policy attitude (0-100 scale)",
color = "Model",
title = .x) +
theme_bw() +
coord_cartesian(ylim = c(45, 60)) +
geom_hline(yintercept = control_mean, linewidth = 1, alpha = 0.5) +
geom_point(data = model_mean_y,
aes(x = param_in_b, y = pred_value),
inherit.aes = F,
alpha = 0.5,
size = 3) +
geom_text_repel(data = model_mean_y,
aes(x = param_in_b, y = pred_value, label = model),
inherit.aes = F) +
theme(legend.position = c(0.85, 0.5),
legend.box.background = element_rect(),
plot.title = element_text(hjust = 0.5),
panel.grid.minor = element_blank())
if(.x == "Log scale") {
g <-
g +
scale_x_log10() +
annotate("text", label = "Mean attitude in control group",
x = 100,
y = control_mean - 0.25,
hjust = 1, fontface = "bold") +
annotate("text", label = "Points show mean attitude in LM groups",
x = log(50, 10),
y = 60,
fontface = "bold")
} else {
g <-
g +
theme(legend.position = "none",
axis.ticks.y = element_blank(),
axis.text.y = element_blank()) +
labs(y = "")
}
g
})
g <- plot_grid(out_plots[[2]], out_plots[[1]], labels = "AUTO")
ggsave(plot = g, filename = "output/plots/nonlinear_comparisons.pdf",
height = 7, width = 14)
# Extrapolation exercise ----
x <- specifications %>% filter(specification == "log-logistic") %>% pull(model_fit) %>% .[[1]]
extrapolate_to_values <- c(3000, 30000) # In billions
plot_extrapolation <-
map(extrapolate_to_values,
function(extrap_value) {
newdata2 <-
data.frame(parameters = c(
seq(from = min(df_for_model2$parameters),
to = max(df_for_model2$parameters),
length.out = 100),
seq(from = max(df_for_model2$parameters) + 1,
to = extrap_value,
length.out = 500)))
df_pred2 <-
predict(x, level = 0, newdata = newdata2) %>%
as.data.frame() %>%
bind_cols(newdata2) %>%
set_names("pred_value", "param_in_b")
df_pred2 <-
df_pred2 %>%
mutate(control_mean = control_mean) %>%
mutate(implied_tx = pred_value - control_mean)
max_tx <- df_pred2 %>% slice_max(param_in_b)
obs_tx <- df_pred2 %>% filter(param_in_b == 300)
obs_color <- "blue"
max_color <- "red"
hum_color <- "green4"
human_mean <-
df_for_model %>%
filter(condition == "human") %>%
pull(dv_response_mean) %>%
mean()
g2 <-
df_pred2 %>%
ggplot(aes(x = param_in_b/1000, y = pred_value)) +
theme_bw() +
geom_line() +
geom_point(data = model_mean_y,
aes(x = param_in_b/1000, y = pred_value),
inherit.aes = F,
alpha = 0.3,
size = 3) +
labs(x = "Parameters (in Trillions)",
y = "Policy attitude (0-100 scale)",
title = "Extrapolation of log-logistic function") +
geom_text_repel(data = model_mean_y %>% mutate(model  = ifelse(param_in_b < 300, NA, model)),
aes(x = param_in_b/1000, y = pred_value, label = model),
inherit.aes = F) +
scale_y_continuous(breaks = 46:60) +
theme(panel.grid.minor.y = element_blank(),
plot.title = element_text(hjust = 0.5)) +
# Annotate implied treatment effects
# Full extrapolation:
annotate("segment",
x    = max_tx$param_in_b/1000,
xend = max_tx$param_in_b/1000,
y    = max_tx$control_mean + 0.1,
yend = max_tx$pred_value - 0.1,
arrow = arrow(ends = "both", type = "closed", length = unit(0.02, "npc")),
color = max_color) +
annotate("text",
x = max_tx$param_in_b/1000*0.99,
y = 55,
hjust = 1,
label = paste0("Parameters: ", max_tx$param_in_b/1000, "T (", max_tx$param_in_b, "B)\n",
"Implied treatment effect: ", max_tx$implied_tx %>% round(2), "pp"),
color = max_color) +
# Empirically observed max
annotate("segment",
x    = 300/1000,
xend = 300/1000,
y    = obs_tx$control_mean + 0.1,
yend = obs_tx$pred_value - 0.1,
arrow = arrow(ends = "both", type = "closed", length = unit(0.02, "npc")),
color = obs_color) +
annotate("text",
x = obs_tx$param_in_b/1000*1.05,
y = 52,
hjust = 0,
label = paste0("Parameters: 0.3T (300B)\nImplied treatment effect: ",
obs_tx$implied_tx %>% round(2), "pp"),
color = obs_color) +
# Add human mean
geom_hline(yintercept = human_mean, linewidth = 1, alpha = 0.5,
color = hum_color) +
annotate("text",
x = (extrap_value/1000)/2,
y = human_mean + 0.25,
hjust = 0.5,
label = "Mean attitude in human-message group",
color = hum_color) +
# Control group mean
geom_hline(yintercept = control_mean, linewidth = 1, alpha = 0.5) +
annotate("text",
label = "Mean attitude in control group",
x = (extrap_value/1000)/2,
y = control_mean - 0.25,
hjust = 0.5)
ggsave(plot = g2,
filename = paste0("output/plots/extrapolation_", extrap_value/1000, "T.pdf"),
height = 7, width = 9)
})
# x <-
#   anova(specifications$model_fit[[1]],
#         specifications$model_fit[[4]])
# Write table to file
# data.frame("Model" = specifications$specification,
#            "AIC" = x$AIC,
#            "BIC" = x$BIC,
#            "LL" = x$logLik) %>%
#   arrange(AIC) %>%
#   mutate_if(is.numeric, ~format(round(., 2), nsmall = 2)) %>%
#   write_csv("output/tables/nonlinear_comparisons.csv")
# map(1:nrow(specifications),
#     function(.x) {
#
#       out <- specifications$model_fit[[.x]] %>% summary
#       out$tTable %>%
#         as.data.frame %>%
#         rownames_to_column() %>%
#         mutate(Model = specifications$specification[[.x]]) %>%
#         rename(Parameter = rowname) %>%
#         select(Model, everything()) %>%
#         mutate(`p-value` = case_when(
#           `p-value` <.001 ~ "<.001",
#           T ~ format(round(`p-value`, 3), nsmall = 3)
#         )) %>%
#         mutate_if(is.numeric, ~format(round(., 2), nsmall = 2))
#
#     }) %>%
#   bind_rows() %>%
#   write_csv("output/tables/nonlinear_results.csv")
library(tidyverse)
library(metafor)
library(broom)
library(estimatr)
library(ggrepel)
library(cowplot)
library(tidybayes)
set.seed(42)
options(scipen = 999)
# Read in data ----
df_for_model <- readRDS("output/processed_data/prepared_data.rds")
# Estimate message-level effects ----
# For each issue fit linear regression to estimate individual message effects
list_issues <- df_for_model %>% pull(issue) %>% unique
out_regs <-
map(list_issues,
function(.x) {
# Fit model for issue .x
reg_model <-
lm_robust(
formula = dv_response_mean ~ 1 + factor(message_id) + party + ideology + knowledge,
data = df_for_model %>% filter(issue == .x)
)
# Get covariance matrix
vcov_matrix <- reg_model$vcov
# Retain only message ID terms in covariance matrix
vcov_matrix <- vcov_matrix[str_detect(rownames(vcov_matrix), "message_id"),
str_detect(colnames(vcov_matrix), "message_id")]
# Get estimates
model_estimates <-
tidy(reg_model) %>%
filter(str_detect(term, "message_id")) %>% # Retain only message ID terms in estimates
mutate(issue = .x)
# Check SEs match
stopifnot(identical(
vcov_matrix %>% diag %>% sqrt %>% unname %>% round(8),
model_estimates$std.error %>% round(8)
))
# Check symmetric
stopifnot(isSymmetric.matrix(vcov_matrix))
# Return
list("estimates" = model_estimates,
"vcov" = vcov_matrix)
})
names(out_regs) <- list_issues
# Bind estimates
df_estimates <-
map(out_regs, ~.x$estimates) %>%
bind_rows()
# Make block diagonal vcov matrix
vcov_block <-
map(out_regs, ~.x$vcov) %>%
bdiag() %>%
as.matrix()
dim(vcov_block)
# Wrangle message-level estimates ----
# Add message-level features
df_estimates <-
df_estimates %>%
rename(message_id = term) %>%
mutate(message_id = as.numeric(str_remove(message_id, "factor\\s*\\([^\\)]+\\)"))) %>%
left_join(df_for_model %>%
#filter(condition != "human") %>%
filter(message_id != 0) %>%
distinct(message_id, .keep_all = T) %>%
select(message_id, model, model_family, issue, treatment_message_word_count, parameters,
moral_nonmoral_ratio, flesch, emotion_proportion, type_token_ratio, starts_with("gpt_"),
valence_correct, task_completion, authorship, pretraining_tokens),
by = c("message_id", "issue")) %>%
# Factor task completion
mutate(task_completion_fac = factor(task_completion))
# Create model categories variable
model_bins <-
list("Human" = "human",
"Small (<=7B)" = df_for_model %>% filter(parameters <= 7) %>% pull(model) %>% unique,
"Medium (9-40B)" = df_for_model %>% filter(parameters > 7 & parameters <= 40) %>% pull(model) %>% unique,
"Large (69-72B)" = df_for_model %>% filter(parameters > 40 & parameters <= 72) %>% pull(model) %>% unique,
"Frontier" = df_for_model %>% filter(str_detect(model, "Claude-3-Opus|GPT-4")) %>% pull(model) %>% unique)
model_names <- df_estimates %>% pull(model) %>% unique
# Attach
df_estimates <-
df_estimates %>%
mutate(model_bins = map(
df_estimates$model,
function(model_y) { model_bins[map(model_bins, ~ model_y %in% .x) %>% unlist] %>% names }) %>% unlist) %>%
mutate(model_bins = factor(model_bins, levels = c("Frontier",
"Large (69-72B)",
"Medium (9-40B)",
"Small (<=7B)",
"Human")),
model_inds = factor(model, levels = c(model_names[str_detect(model_names, "Claude-3-Opus")],
model_names[str_detect(model_names, "Claude-3-Opus", negate = T)])))
# Make model-level means of mediators
mediator_col_names <- c("moral_nonmoral_ratio", "flesch", "emotion_proportion", "type_token_ratio",
"task_completion",  "pretraining_tokens", "treatment_message_word_count")
df_mod_lvl_means <-
df_estimates %>%
reframe(across(all_of(mediator_col_names), ~ mean(.x), .names = "{col}_mod_lvl"), .by = model)
df_estimates <-
df_estimates %>%
left_join(df_mod_lvl_means, by = "model")
saveRDS(df_estimates, "output/processed_data/df_estimates.rds")
# Compute raw model-level ATEs ----
stopifnot(identical(vcov_block %>% diag %>% sqrt %>% round(8), df_estimates$std.error %>% round(8))) # Check SEs match
stopifnot(isSymmetric.matrix(vcov_block)) # Check symmetric
out_raw_mod_ATEs <-
rma.mv(
yi = estimate,
V = vcov_block,
mods = ~ 0 + model,
control = list(rel.tol = 1e-8),
sparse = T,
data = df_estimates
) %>%
tidy() %>%
mutate(lwr = estimate - 1.96*std.error,
upr = estimate + 1.96*std.error) %>%
mutate(term = str_remove(term, "model")) %>%
rename(model = term) %>%
left_join(df_estimates %>% select(model, model_family, parameters) %>% distinct(.keep_all = T), by = "model")
saveRDS(out_raw_mod_ATEs, "output/processed_data/raw_model_ATEs.rds")
# Compute contrast tests ----
out_contrasts <-
rma.mv(
yi = estimate,
V = vcov_block,
mods = ~ 1 + factor(model_inds),
control = list(rel.tol = 1e-8),
sparse = T,
data = df_estimates
) %>%
tidy()
# Wrangle
out_contrasts <-
out_contrasts %>%
mutate(term = str_remove(term, "factor\\s*\\([^\\)]+\\)")) %>%
mutate(estimate_scaled_vs_intercept = case_when(
term != "intercept" ~ estimate + out_contrasts %>% filter(term == "intercept") %>% pull(estimate),
T ~ NA_real_
))
saveRDS(out_contrasts, "output/processed_data/contrasts_vs_claude.rds")
# Fit primary models with parameter count covariate ----
# First define model specifications
# Get specifications for potential mediators
list_mediators <- names(df_estimates)[str_detect(names(df_estimates), "mod_lvl")] %>% map_chr(~paste0(.x, "_z"))
spec_mediators <-
map(list_mediators,
function(.x) {
tribble(
~specification,     ~fixef,                       ~ranef,
.x,                 paste0("~1+", .x),            list("~1|issue",
"~1|message_id",
"~1|model")
)
}) %>%
bind_rows()
# Create all specifications
specifications <-
tribble(
~specification,     ~fixef,                                                            ~ranef,
"linear",           "~1+poly(log_param_count_c, degree=1, raw=TRUE)",                  list("~1+poly(log_param_count_c, degree=1, raw=TRUE)|issue",
"~1|message_id",
"~1|model"),
"family_fixed_fx",  "~1+poly(log_param_count_c, degree=1, raw=TRUE)+model_family",     list("~1+poly(log_param_count_c, degree=1, raw=TRUE)|issue",
"~1|message_id",
"~1|model"),
"quadratic",        "~1+poly(log_param_count_c, degree=2, raw=TRUE)",                  list("~1+poly(log_param_count_c, degree=2, raw=TRUE)|issue",
"~1|message_id",
"~1|model"),
"cubic",            "~1+poly(log_param_count_c, degree=3, raw=TRUE)",                  list("~1+poly(log_param_count_c, degree=3, raw=TRUE)|issue",
"~1|message_id",
"~1|model"),
"mediators_joint",  paste0("~1+", paste0(list_mediators, collapse = "+")),             list("~1|issue",
"~1|message_id",
"~1|model"),
"task_comp2_alone", "~1+poly(task_completion_mod_lvl, degree=2, raw=TRUE)",            list("~1+poly(task_completion_mod_lvl, degree=2, raw=TRUE)|issue",
"~1|message_id",
"~1|model"),
"task_comp3_alone", "~1+poly(task_completion_mod_lvl, degree=3, raw=TRUE)",            list("~1+poly(task_completion_mod_lvl, degree=3, raw=TRUE)|issue",
"~1|message_id",
"~1|model"),
"primary_adjust2", paste0("~1+poly(log_param_count_c, degree=1, raw=TRUE)",
"+poly(task_completion_mod_lvl, degree=2, raw=TRUE)"),       list("~1+poly(log_param_count_c, degree=1, raw=TRUE)|issue",
"~1|message_id",
"~1|model"),
"primary_adjust3", paste0("~1+poly(log_param_count_c, degree=1, raw=TRUE)",
"+poly(type_token_ratio_mod_lvl, degree=2, raw=TRUE)"),      list("~1+poly(log_param_count_c, degree=1, raw=TRUE)|issue",
"~1|message_id",
"~1|model"),
"drop_pythia70m", "~1+poly(log_param_count_c, degree=1, raw=TRUE)",                    list("~1+poly(log_param_count_c, degree=1, raw=TRUE)|issue",
"~1|message_id",
"~1|model")
) %>%
bind_rows(spec_mediators)
# Define n parameters for frontier models (in billions)
upper_b <- 1000
n_p_frontier <- seq(from = 300, to = upper_b, by = 100)
# Define combinations for modelling
df_combos <- crossing(specifications, "frontier_params_in_b" = n_p_frontier)
# Drop redundant rows
df_combos <-
df_combos %>%
mutate(retain = case_when(
specification %in% c(df_combos$specification[df_combos$specification != "linear"] %>% unique) & frontier_params_in_b == 300 ~ 1,
specification == "linear" ~ 1,
T ~ 0
)) %>%
filter(retain == 1)
# Now fit the models!
out_models <- list()
df_combos
# Drop human estimates
drop_humans       <- df_estimates$model != "human"
df_estimates_temp <- df_estimates[drop_humans,]
vcov_block_temp   <- vcov_block[drop_humans, drop_humans]
id_params <- 300
df_combos
i <- 6
id_spec   <- df_combos[[i,"specification"]]
id_fixef  <- df_combos[[i,"fixef"]]
id_ranef  <- df_combos[[i,"ranef"]]
id_params <- df_combos[[i,"frontier_params_in_b"]]
# If spec is drop pythia-70m then also do that
if(id_spec == "drop_pythia70m") {
drop_pythia       <- df_estimates_temp$model != "Pythia-70M"
df_estimates_temp <- df_estimates_temp[drop_pythia,]
vcov_block_temp   <- vcov_block_temp[drop_pythia, drop_pythia]
}
stopifnot(identical(vcov_block_temp %>% diag %>% sqrt %>% round(8), df_estimates_temp$std.error %>% round(8))) # Check SEs match
stopifnot(isSymmetric.matrix(vcov_block_temp)) # Check symmetric
# Wrangle parameter count variable
df_estimates_temp <-
df_estimates_temp %>%
# Parameter count variable
mutate(parameters = ifelse(is.na(parameters), id_params, parameters)) %>% # Impute parameter count for frontier models
mutate(param_count = parameters*1e9) %>%  # Get parameter count on full scale
mutate(log_param_count = log(param_count)) %>% # Log it
mutate(log_param_count_c = as.numeric(scale(log_param_count, center = T, scale = F))) %>% # Center it
# Z-score mediators
mutate(across(str_remove_all(list_mediators, "_z"), ~ as.numeric(scale(.x)), .names = "{col}_z"))
id_fixef
id_fixef <- "~1+parameters+poly(task_completion_mod_lvl, degree=2, raw=TRUE)"
df_estimates_temp
as.formula(id_fixef)
map(id_ranef[[1]], ~as.formula(.x))
id_ranef[[1]]
id_ranef[[1]][[1]]
id_ranef[[1]][[1]] <- "~1+parameters|issue"
map(id_ranef[[1]], ~as.formula(.x))
df_estimates_temp$parameters
# Fit
out_models[[i]] <-
rma.mv(
yi = estimate,
V = vcov_block_temp,
mods = as.formula(id_fixef),
random = map(id_ranef[[1]], ~as.formula(.x)),
struct = "GEN",
control = list(
rel.tol = 1e-8
# optimizer = "optimParallel",
# ncpus = parallel::detectCores()
),
sparse = T,
data = df_estimates_temp
)
out_models
